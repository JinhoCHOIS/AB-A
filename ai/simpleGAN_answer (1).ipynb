{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"GAN.JPG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#노이즈 z = 128, 등의 랜덤값을 넣어 0~9까지의 fake data생성\n",
    "#discriminator에 input이 2번 들어감 교차해서 배치하듯이 들어감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST and load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 11s 1us/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import shutil\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(train_data, train_label), (test_data, test_label) = mnist.load_data()\n",
    "train_data = train_data / 255.\n",
    "test_data = test_data / 255.\n",
    "\n",
    "def img_tile(imgs, aspect_ratio=1.0, tile_shape=None, border=1,\n",
    "             border_color=0):\n",
    "    ''' Tile images in a grid.\n",
    "    If tile_shape is provided only as many images as specified in tile_shape\n",
    "    will be included in the output.\n",
    "    '''\n",
    "    imgs = np.array(imgs)\n",
    "    if imgs.ndim != 3 and imgs.ndim != 4:\n",
    "        raise ValueError('imgs has wrong number of dimensions.')\n",
    "    n_imgs = imgs.shape[0]\n",
    "\n",
    "    # Grid shape\n",
    "    img_shape = np.array(imgs.shape[1:3])\n",
    "    if tile_shape is None:\n",
    "        img_aspect_ratio = img_shape[1] / float(img_shape[0])\n",
    "        aspect_ratio *= img_aspect_ratio\n",
    "        tile_height = int(np.ceil(np.sqrt(n_imgs * aspect_ratio)))\n",
    "        tile_width = int(np.ceil(np.sqrt(n_imgs / aspect_ratio)))\n",
    "        grid_shape = np.array((tile_height, tile_width))\n",
    "    else:\n",
    "        assert len(tile_shape) == 2\n",
    "        grid_shape = np.array(tile_shape)\n",
    "\n",
    "    # Tile image shape\n",
    "    tile_img_shape = np.array(imgs.shape[1:])\n",
    "    tile_img_shape[:2] = (img_shape[:2] + border) * grid_shape[:2] - border\n",
    "\n",
    "    # Assemble tile image\n",
    "    tile_img = np.empty(tile_img_shape)\n",
    "    tile_img[:] = border_color\n",
    "    for i in range(grid_shape[0]):\n",
    "        for j in range(grid_shape[1]):\n",
    "            img_idx = j + i * grid_shape[1]\n",
    "            if img_idx >= n_imgs:\n",
    "                # No more images - stop filling out the grid.\n",
    "                break\n",
    "            img = imgs[img_idx]\n",
    "            yoff = (img_shape[0] + border) * i\n",
    "            xoff = (img_shape[1] + border) * j\n",
    "            tile_img[yoff:yoff + img_shape[0], xoff:xoff + img_shape[1], ...] = img\n",
    "\n",
    "    return tile_img\n",
    "\n",
    "\n",
    "def plot_network_output(data, reconst_data, generated, step):\n",
    "    num = 8\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=3, ncols=num, figsize=(18, 6))\n",
    "    for i in xrange(num):\n",
    "        ax[(0, i)].imshow(np.squeeze(generated[i]), cmap=plt.cm.gray)\n",
    "        ax[(1, i)].imshow(np.squeeze(data[i]), cmap=plt.cm.gray)\n",
    "        ax[(2, i)].imshow(np.squeeze(reconst_data[i]), cmap=plt.cm.gray)\n",
    "        ax[(0, i)].axis('off')\n",
    "        ax[(1, i)].axis('off')\n",
    "        ax[(2, i)].axis('off')\n",
    "\n",
    "    fig.suptitle('Top: generated | Middle: data | Bottom: recunstructed')\n",
    "#     plt.show()\n",
    "    plt.savefig(IMAGE_DIR + '/{}.png'.format(str(step).zfill(6)))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# size of MNIST\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9571262ba8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[0], 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data\n",
    "idx = np.random.randint(0, train_data.shape[0])\n",
    "_, (ax1, ax2) = plt.subplots(1, 2)\n",
    "sample_data = train_data[idx]\n",
    "# ax1.imshow(sample_data, cmap=plt.cm.Greys);\n",
    "ax1.imshow(np.array(sample_data*255, dtype=np.uint8), 'gray')\n",
    "ax2.hist(sample_data, bins=20, range=[0, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete summary folder and make it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_DIR = './gan_summary'\n",
    "TRAIN_DIR = SUMMARY_DIR + '/train'\n",
    "TEST_DIR = SUMMARY_DIR + '/test'\n",
    "IMAGE_DIR = SUMMARY_DIR + '/image'\n",
    "\n",
    "if os.path.exists(SUMMARY_DIR):\n",
    "    shutil.rmtree(SUMMARY_DIR)\n",
    "if not os.path.exists(SUMMARY_DIR):\n",
    "    os.makedirs(SUMMARY_DIR)\n",
    "    os.makedirs(TRAIN_DIR)\n",
    "    os.makedirs(TEST_DIR)\n",
    "    os.makedirs(IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-05ebbc161a61>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-05ebbc161a61>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    weights =\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def fully_connected(inputs, out_channel, name='fc'):\n",
    "    \"\"\"\n",
    "    very simple fully connected layer function\n",
    "\n",
    "    Args:\n",
    "        inputs: a batch of input tensor [batch_size, n]\n",
    "                where n is the number of input feature dimension\n",
    "        out_channel: output channel dimension\n",
    "\n",
    "    Returns:\n",
    "        fc: inputs * weights + biases [batch_size, out_channel]\n",
    "    \"\"\"\n",
    "    # Define weight matrix variable, bias vector variable\n",
    "    with tf.variable_scope(name):\n",
    "        # To share the variables you have to use\n",
    "        # a function 'tf.get_variable' instead of 'tf.Variable'\n",
    "        weights = \n",
    "        biases = \n",
    "\n",
    "        fc = \n",
    "\n",
    "        return fc\n",
    "\n",
    "\n",
    "def discriminator(x, reuse=None):\n",
    "    \"\"\"\n",
    "    build the discriminator\n",
    "\n",
    "    Args:\n",
    "        x: a batch of input to the network [batch_size, 28, 28, 1]\n",
    "\n",
    "    returns:\n",
    "        net: output of the discriminator [batch_size, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        # Vectorize the input x\n",
    "        # Fully connected layer with 256 output units and 'fc1' as its name\n",
    "        # Apply non-linearity function 'relu'\n",
    "        # Fully connected layer with 1 output units and 'fc2' as its name\n",
    "        # Apply non-linearity function 'sigmoid'\n",
    "        # Return the final tensor\n",
    "        net = \n",
    "        net = \n",
    "        net = \n",
    "        net = \n",
    "        net = \n",
    "        return net\n",
    "\n",
    "\n",
    "def generator(z):\n",
    "    \"\"\"\n",
    "    build the generator\n",
    "\n",
    "    Args:\n",
    "        z: a batch of input to the network [batch_size, z_dim]\n",
    "\n",
    "    Returns:\n",
    "        net: output of the generator [batch_size, 28, 28, 1]\n",
    "    \"\"\"\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "\n",
    "        # Unlike the discriminator, input z is a set of vectors\n",
    "        \n",
    "        # Fully connected layer with 256 output units and 'fc1' as its name\n",
    "        # Apply non-linearity function 'relu'\n",
    "        # Fully connected layer with 784 output units and 'fc2' as its name\n",
    "        # Apply non-linearity function 'sigmoid'\n",
    "        # Reshape final output to be a proper image file [28, 28, 1]\n",
    "        # Return the final tensor\n",
    "        net = \n",
    "        net = \n",
    "        net = \n",
    "        net = \n",
    "        net = \n",
    "        return net\n",
    "\n",
    "\n",
    "def get_loss(D_real, D_fake, eps=1e-10):\n",
    "    \"\"\"\n",
    "    get loss of GAN\n",
    "\n",
    "    Args:\n",
    "        D_real: Real Discriminator output [batch_size, 1]\n",
    "        D_rake: Fake discriminator output [batch_size, 1]\n",
    "\n",
    "    Returns:\n",
    "        D_loss: Discriminator loss\n",
    "        G_loss: Generator loss\n",
    "    \"\"\"\n",
    "    D_loss = \n",
    "    G_loss = \n",
    "\n",
    "    return D_loss, G_loss\n",
    "\n",
    "\n",
    "def get_next_batch(data, label, batch_size):\n",
    "    \"\"\"\n",
    "    get 'batch_size' amount of data and label randomly\n",
    "\n",
    "    Args:\n",
    "        data: data\n",
    "        label: label\n",
    "        batch_size: # of data to get\n",
    "\n",
    "    Returns:\n",
    "        batch_data: data of 'batch_size'\n",
    "        batch_label: coresponding label of batch_data\n",
    "    \"\"\"\n",
    "    n_data = data.shape[0]\n",
    "    random_idx = random.sample(range(1, n_data), batch_size)\n",
    "\n",
    "    batch_data = data[random_idx]\n",
    "    batch_label = label[random_idx]\n",
    "    return batch_data, batch_label\n",
    "\n",
    "\n",
    "# Set hyperparameters\n",
    "batch_size = 100\n",
    "z_dim = 128\n",
    "max_step = 20000\n",
    "lr = 0.001\n",
    "beta1 = 0.9\n",
    "\n",
    "train_data = np.expand_dims(train_data, 3)\n",
    "test_data = np.expand_dims(test_data, 3)\n",
    "\n",
    "############################# Build the model #############################\n",
    "# Define image tensor x placeholder\n",
    "x = tf.placeholder(tf.float32, [batch_size, 28, 28, 1], name='input_x')\n",
    "# Define z vector as uniform distribution between [-1, 1]\n",
    "z = tf.random_uniform((batch_size, z_dim), -1., 1., name='latent_z')\n",
    "\n",
    "# Build discriminator where input data is real image x\n",
    "D_real = discriminator(x, reuse=False)\n",
    "# Build generator\n",
    "G = generator(z)\n",
    "# Build discriminator where input data is generated image G\n",
    "D_fake = discriminator(G, reuse=True)\n",
    "\n",
    "# Get D_loss and G_loss\n",
    "D_loss, G_loss = get_loss(D_real, D_fake)\n",
    "\n",
    "# Make optimization op\n",
    "opt = tf.train.AdamOptimizer(lr, beta1=beta1)\n",
    "\n",
    "# To update the generator and the discriminator\n",
    "# get their network parameters\n",
    "G_params = [param for param in tf.trainable_variables()\n",
    "            if 'generator' in param.name]\n",
    "D_params = [param for param in tf.trainable_variables()\n",
    "            if 'discriminator' in param.name]\n",
    "\n",
    "# Make train op for each network\n",
    "D_train = opt.minimize(D_loss, var_list=D_params)\n",
    "G_train = opt.minimize(G_loss, var_list=G_params)\n",
    "\n",
    "# Make initialization op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Add summary and make op to add summary data to event log\n",
    "tf.summary.scalar('Generator_loss', G_loss)\n",
    "tf.summary.scalar('Discriminator_loss', D_loss)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Define writer\n",
    "    train_writer = tf.summary.FileWriter(TRAIN_DIR, sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(TEST_DIR)\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Before train the model, shows train data and save it\n",
    "    batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "    train_tiled = img_tile(batch_x, border_color=1.0)\n",
    "    train_tiled = np.squeeze(train_tiled)\n",
    "    print(\"Training data\")\n",
    "    plt.imshow(train_tiled, cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    plt.imsave(IMAGE_DIR + '/train.png', train_tiled, cmap=plt.cm.gray)\n",
    "    \n",
    "    samples = []\n",
    "    for step in range(max_step):\n",
    "        batch_x, batch_y = get_next_batch(train_data, train_label, batch_size)\n",
    "        \n",
    "        _, d_loss = sess.run([D_train, D_loss], feed_dict={x: batch_x})\n",
    "        _, g_loss = sess.run([G_train, G_loss])\n",
    "        summary = sess.run(merged, feed_dict={x: batch_x})\n",
    "        train_writer.add_summary(summary, step)\n",
    "        \n",
    "        # Save generarted data to make gif files\n",
    "        if step % 50 == 0:\n",
    "            g = sess.run(G)\n",
    "            g_tiled = img_tile(g, border_color=1.0)\n",
    "            g_tiled = np.squeeze(g_tiled)\n",
    "            samples.append(g_tiled)\n",
    "        if step % 200 == 0:\n",
    "            print(\"{} steps |  G_loss: {:.4f}, D_loss: {:.4f}\".format(step, g_loss, d_loss))\n",
    "            plt.imshow(g_tiled, cmap=plt.cm.gray)\n",
    "            plt.show()\n",
    "            plt.imsave(IMAGE_DIR + '/{}.png'.format(str(step).zfill(6)),\n",
    "                       g_tiled, cmap=plt.cm.gray)\n",
    "#             plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "# Make gif files\n",
    "imageio.mimsave(SUMMARY_DIR + '/generated.gif', samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
